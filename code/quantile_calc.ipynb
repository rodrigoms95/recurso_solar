{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3.\n",
    "# Mapeo de cuantiles empírico.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de archivos.\n",
    "path_d = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas.nc\"\n",
    "path_r = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_m = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_q = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "\n",
    "# Datos medidos.\n",
    "ds_d = xr.open_dataset( path_d )\n",
    "# Modelo histórico original.\n",
    "ds_r = xr.open_dataset( path_r )\n",
    "# Modelo histórico corregido, copia del archivo del modelo histórico original.\n",
    "ds_m = xr.open_dataset( path_r )\n",
    "# Mapeo de cuantiles, calculado en pasos anteriores.\n",
    "ds_q = xr.open_dataset( path_r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el archivo de mapeo de cuantiles.\n",
    "\n",
    "# Rutas de archivos.\n",
    "path_r = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_q = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "\n",
    "# Abrimos el archivo.\n",
    "with xr.open_dataset( path_r ) as ds:\n",
    "\n",
    "    # Cambiamos tiempo por la distribución acumulada.\n",
    "    CDF = np.linspace( 1/ds_r[\"time\"].shape[0], 1, ds_r[\"time\"].shape[0] )\n",
    "    ds[\"time\"] = CDF\n",
    "\n",
    "    # Guardamos le archivo.\n",
    "    ds.to_netcdf(path_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos para todas las latitudes y longitudes.\n",
    "for lat in ds_d[\"lat\"]:\n",
    "    print(f\"Procesando latitud {lat:.2f}...\")\n",
    "    for lon in ds_d[\"lon\"]:\n",
    "\n",
    "        df_d = ds_d.sel( {\"lat\": lat, \"lon\": lon} ).to_dataframe(\n",
    "            ).reset_index().set_index(\"time\")\n",
    "        df_r = ds_r.sel( {\"lat\": lat, \"lon\": lon} ).to_dataframe(\n",
    "            ).reset_index().set_index(\"time\")\n",
    "\n",
    "        # Creamos DataFrames de apoyo.\n",
    "        df_m = df_r.copy()\n",
    "        df_q = pd.DataFrame( index = np.linspace(\n",
    "            1/df_r.shape[0], 1, df_r.shape[0] ),\n",
    "            columns = df_r.columns )\n",
    "        df_q = df_q.rename_axis(\"CDF\", axis = 0)\n",
    "\n",
    "        # Inicializamos las variables como 0.\n",
    "        df_m[ [\"GHI\", \"DNI\"] ] = 0\n",
    "\n",
    "        # Iteramos para todas las columnas.\n",
    "        for v in df_d.columns:\n",
    "            # Ordenamos los valores originales y destino incluyendo el tiempo.\n",
    "            if v in [\"DNI\", \"GHI\"]:\n",
    "                df_i = df_d[[v]].where( df_d[[v]] > 0, np.nan\n",
    "                    ).dropna().sort_values(v).reset_index()\n",
    "                df_j = df_r[[v]].where( df_r[[v]] > 0, np.nan\n",
    "                    ).dropna().sort_values(v).reset_index()\n",
    "            else:\n",
    "                df_i = df_d[[v]].sort_values(v).reset_index()\n",
    "                df_j = df_r[[v]].sort_values(v).reset_index()\n",
    "            # Calculamos la distribución acumulada.\n",
    "            df_i[\"CDF\"] = np.linspace( 1/df_i.shape[0], 1, df_i.shape[0] )\n",
    "            df_j[\"CDF\"] = np.linspace( 1/df_j.shape[0], 1, df_j.shape[0] )\n",
    "\n",
    "            # Interpolamos los valores de la distribución origen a la destino.\n",
    "            df_j[\"Map\"] = np.interp( df_j[\"CDF\"], df_i[\"CDF\"],\n",
    "                df_i[v] ).round( decimals = 2 )\n",
    "            df_j[\"Quantile\"] =  df_j[\"Map\"] - df_j[v]\n",
    "            df_j = df_j.set_index(\"time\").sort_index()\n",
    "            # Reordenamos los valores.\n",
    "            df_m.loc[ df_j.index, v ] = df_j[\"Map\"]\n",
    "            # Guardamos el mapeo de cuantiles para la corrida futura.\n",
    "            df_j = df_j.set_index(\"CDF\").sort_index()\n",
    "            if v in [\"DNI\", \"GHI\"]:\n",
    "                q = np.interp( df_q.index, df_j.index, \n",
    "                    df_j[\"Quantile\"].values )\n",
    "            else: q = df_j[\"Quantile\"].values\n",
    "            df_q[v] = q\n",
    "\n",
    "        # Nos aseguramos que los datos estén dentro de su rango.\n",
    "        df_m[\"Relative Humidity\"] = df_m[\"Relative Humidity\"].where(\n",
    "            df_m[\"Relative Humidity\"] > 0, 0 )\n",
    "        df_m[\"Relative Humidity\"] = df_m[\"Relative Humidity\"].where(\n",
    "            df_m[\"Relative Humidity\"] < 100, 100 )\n",
    "        df_m[\"Wind Direction\"] = df_m[\"Wind Direction\"].where(\n",
    "            df_m[\"Wind Direction\"] < 360, df_m[\"Wind Direction\"] - 360 )\n",
    "        df_m[\"Wind Speed\"] = df_m[\"Wind Speed\"].where(\n",
    "            df_m[\"Wind Speed\"] > 0 , 0 )\n",
    "        df_m[\"GHI\"] = df_m[\"GHI\"].where( df_m[\"GHI\"] > 0 , 0 )\n",
    "        df_m[\"DNI\"] = df_m[\"DNI\"].where( df_m[\"DNI\"] > 0 , 0 )\n",
    "\n",
    "        # Asignamos al Dataset.\n",
    "        ds_m.loc[ {\"lat\": lat, \"lon\": lon} ] = df_m.reset_index().set_index(\n",
    "            [\"time\", \"lat\", \"lon\"] ).astype(float).to_xarray()\n",
    "        ds_q.loc[ {\"lat\": lat, \"lon\": lon} ] = df_q.reset_index(\n",
    "            ).set_index( [\"CDF\", \"lat\", \"lon\"] ).astype(float).to_xarray()\n",
    "        \n",
    "# Guardamos los archivos.\n",
    "ds_m = ds_m.to_netcdf(path_m, mode = \"w\")\n",
    "ds_q = ds_m.to_netcdf(path_q, mode = \"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
