{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrección de cuantiles empírica.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "i = sys.argv[1]\n",
    "v = \"UVHI\"\n",
    "dims = [\"time\", \"lat\", \"lon\"]\n",
    "\n",
    "path_d    = f\"../temp/NSRDB_4km/grid/WRF_1985_2014_4km_{i}.nc\"\n",
    "path_m    = f\"../temp/WRF_1985_2014_4km/radiacion/WRF_1985_2014_4km_{i}.nc\"\n",
    "#path_f    = \"../temp/WRF_2040_regrid_CHIRPS_days_cdf.nc\"\n",
    "path_res  = f\"../temp/NSRDB_4km/map_res/WRF_regrid_CHIRPS_days_map_{i}.nc\"\n",
    "path_map  = f\"../temp/NSRDB_4km/map/WRF_regrid_CHIRPS_days_qmap_{i}.nc\"\n",
    "#path_fmap = \"../temp/WRF_2040_regrid_CHIRPS_days_qmap.nc\"\n",
    "\n",
    "sum = True\n",
    "\n",
    "with xr.open_dataset(path_m) as ds_m:\n",
    "    with xr.open_dataset(path_d) as ds_d:\n",
    "        #with xr.open_dataset(path_f) as ds_f:\n",
    "\n",
    "            df_d = ds_d.to_dataframe().sort_index()\n",
    "            df_m = ds_m.to_dataframe().sort_index()\n",
    "            #df_f = ds_f.to_dataframe().sort_index()\n",
    "            #df_f[\"map\"] = None\n",
    "            df_m[\"map\"] = None\n",
    "            df_m[\"diff_sum\"] = None\n",
    "            #df_m[\"diff_div\"] = None\n",
    "\n",
    "            latitude = df_d.index.get_level_values(dims[1]).unique()\n",
    "            longitude = df_d.index.get_level_values(dims[2]).unique()\n",
    "\n",
    "            for lat in latitude:\n",
    "                print(f\"{lat:.3f}°N\")\n",
    "                for lon in longitude:\n",
    "                    df_xs_m = df_m.loc[ (slice(None), lat, lon),\n",
    "                        df_m.columns ].sort_values(\"q_model\")\n",
    "                    df_xs_d = df_d.loc[ (slice(None), lat, lon),\n",
    "                        df_d.columns ].sort_values(\"q_model\")\n",
    "                    df_xs_m[\"map\"] = np.interp( df_xs_m[\"q_model\"].values,\n",
    "                        df_xs_d[\"q_model\"].values, df_xs_d[v].values )\n",
    "                    df_xs_m[\"map\"] = df_xs_m[\"map\"].where(df_xs_m[\"map\"]>0, 0)\n",
    "                    df_xs_m[\"diff_sum\"] = df_xs_m[\"map\"] - df_xs_m[v]\n",
    "                    df_m.loc[ (slice(None), lat, lon), df_m.columns ] = df_xs_m\n",
    "                    #df_xs_m[\"diff_div\"] = df_xs_m[\"map\"] / df_xs_m[v]\n",
    "\n",
    "                    #df_xs_f = df_f.loc[ (slice(None), lat, lon), \n",
    "                    #    df_f.columns ].sort_values(\"q_model\")\n",
    "                    #if sum:\n",
    "                    #df_xs_f[\"map\"] = np.interp( df_xs_f[\"q_model\"].values,\n",
    "                    #    df_xs_m[\"q_model\"].values,\n",
    "                    #    df_xs_m[\"diff_sum\"].values )\n",
    "                    #df_xs_f[\"map\"] = df_xs_f[\"map\"] + df_xs_f[v]\n",
    "                    #else:\n",
    "                    #    df_xs_f[\"map\"] = np.interp( df_xs_f[\"q_model\"].values,\n",
    "                    #        df_xs_m[\"q_model\"].values,\n",
    "                    #        df_xs_m[\"diff_div\"].values )\n",
    "                    #    df_xs_f[\"map\"] = df_xs_f[\"map\"] * df_xs_f[v]\n",
    "                    #df_xs_f[\"map\"] = df_xs_f[\"map\"].where(df_xs_f[\"map\"]>0, 0)\n",
    "                    #df_f.loc[ (slice(None), lat, lon), df_f.columns ] = df_xs_f\n",
    "\n",
    "            ds_map = df_m.to_xarray()\n",
    "            ds_m[\"map\"] = ( dims, ds_map[\"map\"].values )\n",
    "            ds_m[\"diff_sum\"] = ( dims, ds_map[\"diff_sum\"].values )\n",
    "            #ds_m[\"diff_div\"] = ( dims, ds_map[\"diff_div\"].values )\n",
    "            ds_m.to_netcdf( path_res )\n",
    "            ds_m[[\"map\"]].rename( {\"map\": v} ).to_netcdf( path_map )\n",
    "\n",
    "            #ds_fmap = df_f.to_xarray()\n",
    "            #ds_f[\"map\"] = ( dims, ds_fmap[\"map\"].values )\n",
    "            #ds_f[[\"map\"]].rename( {\"map\": v} ).to_netcdf( path_fmap )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3.\n",
    "# Mapeo de cuantiles empírico.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de archivos.\n",
    "path_d = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas.nc\"\n",
    "path_r = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_m = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_q = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "\n",
    "# Datos medidos.\n",
    "ds_d = xr.open_dataset( path_d )\n",
    "# Modelo histórico original.\n",
    "ds_r = xr.open_dataset( path_r )\n",
    "# Modelo histórico corregido, copia del archivo del modelo histórico original.\n",
    "ds_m = xr.open_dataset( path_r )\n",
    "# Mapeo de cuantiles, calculado en pasos anteriores.\n",
    "ds_q = xr.open_dataset( path_r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el archivo de mapeo de cuantiles.\n",
    "\n",
    "# Rutas de archivos.\n",
    "path_r = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "path_q = \"/Users/rodrigo/Desktop/zzR_zz_Mega_Variables_Extraidas_2.nc\"\n",
    "\n",
    "# Abrimos el archivo.\n",
    "with xr.open_dataset( path_r ) as ds:\n",
    "\n",
    "    # Cambiamos tiempo por la distribución acumulada.\n",
    "    CDF = np.linspace( 1/ds_r[\"time\"].shape[0], 1, ds_r[\"time\"].shape[0] )\n",
    "    ds[\"time\"] = CDF\n",
    "\n",
    "    # Guardamos le archivo.\n",
    "    ds.to_netcdf(path_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos para todas las latitudes y longitudes.\n",
    "for lat in ds_d[\"lat\"]:\n",
    "    print(f\"Procesando latitud {lat:.2f}...\")\n",
    "    for lon in ds_d[\"lon\"]:\n",
    "\n",
    "        df_d = ds_d.sel( {\"lat\": lat, \"lon\": lon} ).to_dataframe(\n",
    "            ).reset_index().set_index(\"time\")\n",
    "        df_r = ds_r.sel( {\"lat\": lat, \"lon\": lon} ).to_dataframe(\n",
    "            ).reset_index().set_index(\"time\")\n",
    "\n",
    "        # Creamos DataFrames de apoyo.\n",
    "        df_m = df_r.copy()\n",
    "        df_q = pd.DataFrame( index = np.linspace(\n",
    "            1/df_r.shape[0], 1, df_r.shape[0] ),\n",
    "            columns = df_r.columns )\n",
    "        df_q = df_q.rename_axis(\"CDF\", axis = 0)\n",
    "\n",
    "        # Inicializamos las variables como 0.\n",
    "        df_m[ [\"GHI\", \"DNI\"] ] = 0\n",
    "\n",
    "        # Iteramos para todas las columnas.\n",
    "        for v in df_d.columns:\n",
    "            # Ordenamos los valores originales y destino incluyendo el tiempo.\n",
    "            if v in [\"DNI\", \"GHI\"]:\n",
    "                df_i = df_d[[v]].where( df_d[[v]] > 0, np.nan\n",
    "                    ).dropna().sort_values(v).reset_index()\n",
    "                df_j = df_r[[v]].where( df_r[[v]] > 0, np.nan\n",
    "                    ).dropna().sort_values(v).reset_index()\n",
    "            else:\n",
    "                df_i = df_d[[v]].sort_values(v).reset_index()\n",
    "                df_j = df_r[[v]].sort_values(v).reset_index()\n",
    "            # Calculamos la distribución acumulada.\n",
    "            df_i[\"CDF\"] = np.linspace( 1/df_i.shape[0], 1, df_i.shape[0] )\n",
    "            df_j[\"CDF\"] = np.linspace( 1/df_j.shape[0], 1, df_j.shape[0] )\n",
    "\n",
    "            # Interpolamos los valores de la distribución origen a la destino.\n",
    "            df_j[\"Map\"] = np.interp( df_j[\"CDF\"], df_i[\"CDF\"],\n",
    "                df_i[v] ).round( decimals = 2 )\n",
    "            df_j[\"Quantile\"] =  df_j[\"Map\"] - df_j[v]\n",
    "            df_j = df_j.set_index(\"time\").sort_index()\n",
    "            # Reordenamos los valores.\n",
    "            df_m.loc[ df_j.index, v ] = df_j[\"Map\"]\n",
    "            # Guardamos el mapeo de cuantiles para la corrida futura.\n",
    "            df_j = df_j.set_index(\"CDF\").sort_index()\n",
    "            if v in [\"DNI\", \"GHI\"]:\n",
    "                q = np.interp( df_q.index, df_j.index, \n",
    "                    df_j[\"Quantile\"].values )\n",
    "            else: q = df_j[\"Quantile\"].values\n",
    "            df_q[v] = q\n",
    "\n",
    "        # Nos aseguramos que los datos estén dentro de su rango.\n",
    "        df_m[\"Relative Humidity\"] = df_m[\"Relative Humidity\"].where(\n",
    "            df_m[\"Relative Humidity\"] > 0, 0 )\n",
    "        df_m[\"Relative Humidity\"] = df_m[\"Relative Humidity\"].where(\n",
    "            df_m[\"Relative Humidity\"] < 100, 100 )\n",
    "        df_m[\"Wind Direction\"] = df_m[\"Wind Direction\"].where(\n",
    "            df_m[\"Wind Direction\"] < 360, df_m[\"Wind Direction\"] - 360 )\n",
    "        df_m[\"Wind Speed\"] = df_m[\"Wind Speed\"].where(\n",
    "            df_m[\"Wind Speed\"] > 0 , 0 )\n",
    "        df_m[\"GHI\"] = df_m[\"GHI\"].where( df_m[\"GHI\"] > 0 , 0 )\n",
    "        df_m[\"DNI\"] = df_m[\"DNI\"].where( df_m[\"DNI\"] > 0 , 0 )\n",
    "\n",
    "        # Asignamos al Dataset.\n",
    "        ds_m.loc[ {\"lat\": lat, \"lon\": lon} ] = df_m.reset_index().set_index(\n",
    "            [\"time\", \"lat\", \"lon\"] ).astype(float).to_xarray()\n",
    "        ds_q.loc[ {\"lat\": lat, \"lon\": lon} ] = df_q.reset_index(\n",
    "            ).set_index( [\"CDF\", \"lat\", \"lon\"] ).astype(float).to_xarray()\n",
    "        \n",
    "# Guardamos los archivos.\n",
    "ds_m = ds_m.to_netcdf(path_m, mode = \"w\")\n",
    "ds_q = ds_m.to_netcdf(path_q, mode = \"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
